{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Forecasting with various models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-18 14:05:13.729533: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-07-18 14:05:13.739176: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-18 14:05:13.739207: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-paper')\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('seaborn')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from pmdarima.metrics import smape\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import os,sys\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(test_y, pred_y):\n",
    "    mae = mean_absolute_error(test_y, pred_y)\n",
    "    mape = mean_absolute_percentage_error(test_y, pred_y)\n",
    "    rmse = mean_squared_error(test_y, pred_y, squared=False)\n",
    "    smaperror = smape(test_y, pred_y)\n",
    "    r2 = r2_score(test_y, pred_y)\n",
    "    return round(mae, 3), round(mape, 3), round(rmse, 3), round(smaperror, 3), round(r2, 3)\n",
    "\n",
    "def print_metrics(mae, mape, rmse, smaperror, r2):\n",
    "    print('Mean Absolute Error: %.3f' % mae)\n",
    "    print('Mean Absolute Percentage Error: %.3f' % mape)\n",
    "    print('Root Mean Squared Error: %.3f' % rmse)\n",
    "    print('Symmetric Mean Absolute Percentage Error: %.3f' % smaperror)\n",
    "    print('R^2: %.3f' % r2)\n",
    "\n",
    "def get_percentage(test_y, pred_y, train_y_last):\n",
    "    true_updowns, pred_updowns = [], []\n",
    "    previous_perf = np.concatenate([train_y_last.reshape(-1,1), test_y])[:-1]\n",
    "    previous_perf_pred = np.concatenate([train_y_last.reshape(-1,1), pred_y.reshape(-1,1)])[:-1]\n",
    "    # compare previous_perf with test_y and pred_y\n",
    "    for i in range(test_y.shape[0]):\n",
    "        if previous_perf[i] < test_y[i]:\n",
    "            true_updowns.append(1)\n",
    "        elif previous_perf[i]> test_y[i]:\n",
    "            true_updowns.append(0)\n",
    "        elif previous_perf[i]== test_y[i]:\n",
    "            true_updowns.append(2)\n",
    "        else:\n",
    "            pass\n",
    "        if previous_perf_pred[i] < pred_y[i]:\n",
    "            pred_updowns.append(1)\n",
    "        elif previous_perf_pred[i]> pred_y[i]:\n",
    "            pred_updowns.append(0)\n",
    "        elif previous_perf_pred[i]== pred_y[i]:\n",
    "            pred_updowns.append(2)\n",
    "        else:\n",
    "            pass\n",
    "    # find percentage\n",
    "    pred_corrects = 0\n",
    "    for i in range(len(pred_updowns)):\n",
    "        if pred_updowns[i] == true_updowns[i]:\n",
    "            pred_corrects += 1\n",
    "    return pred_corrects\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "def plot_train_test(data, train_size, player_name):\n",
    "    # plot train and test set\n",
    "    plt.figure(figsize=(15,8), dpi=100);\n",
    "    plt.grid(True)\n",
    "    plt.ylim(4, 10.2)\n",
    "    plt.plot(data[:train_size], alpha=0.6, linewidth=1.90, label=\"Train Values\", color='blue');\n",
    "    plt.plot(data[train_size:], alpha=0.85, linewidth=1.90, label=\"Test Values\", color='blue', linestyle=(0, (5, 1)));\n",
    "    plt.ylabel(\"Performance\");\n",
    "    plt.xlabel('Games');\n",
    "    plt.title('All '+ str(len(data)) + \" games for \"+ player_name);\n",
    "    plt.legend();\n",
    "    plt.savefig('img/'+player_name+'_train-test.jpg');\n",
    "    # plt.show();\n",
    "    plt.close();\n",
    "\n",
    "def plot_preds_real(data, predictions, train_size, player_name, model_name):\n",
    "    # plot forecasts against actual outcomes\n",
    "    plt.figure(figsize=(15,8), dpi=100);\n",
    "    plt.grid(True)\n",
    "    plt.ylim(5, 10.2)\n",
    "    plt.plot(data[train_size:], alpha=0.85, linewidth=1.90, label=\"Target Values\", color='blue', linestyle=(0, (5, 1)));\n",
    "    plt.plot(predictions, alpha=0.85, linewidth=1.90, label=\"Predicted Values\", color='red');\n",
    "    plt.ylabel(\"Performance\");\n",
    "    plt.xlabel('Games');\n",
    "    plt.title('Next '+str(len(predictions)) + \" games forecasts for \"+player_name+' with '+model_name);\n",
    "    plt.legend();\n",
    "    plt.savefig('img/'+player_name+'_'+model_name+'_forecasts.jpg');\n",
    "    # ax1.show();\n",
    "    plt.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate LSTM Forecast Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_train_predict(player_values=None, input_size = 3, output_size = 1, train_size=200, player_name=None):\n",
    "\t# ensure all data is float\n",
    "\tplayer_values = player_values.astype('float32')\n",
    "\t# frame as supervised learning\n",
    "\treframed = series_to_supervised(player_values, input_size, output_size, dropnan=True)\n",
    "\t# print(reframed.columns.tolist())\n",
    "\tmatchers = ['var10(t)', 'var10(t+']\n",
    "\tmatching = [s for s in reframed.columns.tolist() if any(xs in s for xs in matchers)]\n",
    "\t# print(matching)\n",
    "\tnew_cols = [col for col in reframed.columns if col not in matching] + matching\n",
    "\treframed = reframed[new_cols]\n",
    "\t# print(reframed.columns.tolist())\n",
    "\t# print(reframed.shape)\n",
    "\t# split into train and test sets\n",
    "\tvalues = reframed.values\n",
    "\ttrain = values[:train_size, :]\n",
    "\ttest = values[train_size:, :]\n",
    "\t# split into input and outputs\n",
    "\ttrain_X, train_y = train[:, :-output_size], train[:, -output_size:]\n",
    "\ttest_X, test_y = test[:, :-output_size], test[:, -output_size:]\n",
    "\t# scale X\n",
    "\tsc_x = MinMaxScaler()\n",
    "\ttrain_X = sc_x.fit_transform(train_X)\n",
    "\ttest_X = sc_x.transform(test_X)\n",
    "\t# scale y\n",
    "\tif output_size==1:\n",
    "\t\tsc_y = MinMaxScaler()\n",
    "\t\ttrain_y = sc_y.fit_transform(train_y.reshape(-1, 1))\n",
    "\t\ttest_y = sc_y.transform(test_y.reshape(-1, 1))\n",
    "\telse:\n",
    "\t\tsc_y = MinMaxScaler()\n",
    "\t\ttrain_y = sc_y.fit_transform(train_y)\n",
    "\t\ttest_y = sc_y.transform(test_y)\n",
    "\n",
    "\t# reshape input to be 3D [samples, timesteps, features]\n",
    "\ttrain_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "\ttest_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "\t# print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\t# reshape output into [samples, timesteps, features]\n",
    "\ttrain_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n",
    "\ttest_y = test_y.reshape((test_y.shape[0], test_y.shape[1], 1))\n",
    "\n",
    "\t# define model\n",
    "\tn_timesteps, n_features, n_outputs = train_X.shape[1], train_X.shape[2], train_y.shape[1]\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(20, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "\tmodel.add(RepeatVector(n_outputs))\n",
    "\tmodel.add(LSTM(20, activation='relu', return_sequences=True))\n",
    "\tmodel.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "\tmodel.add(TimeDistributed(Dense(1)))\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "\t# plot_model(model, to_file='img/'+player_name+'_model_lstm.png')\n",
    "\n",
    "\t# fit network\n",
    "\thistory = model.fit(train_X, train_y, epochs=20, batch_size=72, validation_split=0.1, verbose=0, shuffle=False)\n",
    "\t# plot history\n",
    "\tplt.figure(figsize=(15,8), dpi=100, facecolor='white');\n",
    "\tplt.grid(False)\n",
    "\tplt.plot(history.history['loss'], label='train');\n",
    "\tplt.plot(history.history['val_loss'], label='validation', color='orange');\n",
    "\tplt.legend();\n",
    "\tplt.xlabel('Number of epochs')\n",
    "\tplt.ylabel('Loss values')\n",
    "\tplt.title(' Training and Validation Loss with LSTM for '+ player_name)\n",
    "\tplt.savefig('img/'+player_name+'_loss_LSTM.jpg');\n",
    "\t# plt.show();\n",
    "\tplt.close();\n",
    "\n",
    "\t# make a prediction\n",
    "\tyhat = model.predict(test_X)\n",
    "\t# reshape output into [samples, timesteps, features]\n",
    "\ttrain_y = train_y.reshape((train_y.shape[0], train_y.shape[1]))\n",
    "\ttest_y = test_y.reshape((test_y.shape[0], test_y.shape[1]))\n",
    "\tyhat = yhat.reshape((yhat.shape[0], yhat.shape[1]))\n",
    "\n",
    "\tyhat_inversed = sc_y.inverse_transform(yhat)\n",
    "\t# test_y = test_y.reshape((len(test_y), 1))\n",
    "\ttrain_y_inversed = sc_y.inverse_transform(train_y)\n",
    "\ttrain_y_last = train_y_inversed[-1]\n",
    "\ttest_y_inversed = sc_y.inverse_transform(test_y)\n",
    "\treturn test_y_inversed, yhat_inversed, values, train_y_last\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(model = None, player_values=None, input_size = 3, output_size = 1, train_size=None, player_name=None):\n",
    "\t# ensure all data is float\n",
    "\tplayer_values = player_values.astype('float32')\n",
    "\t# frame as supervised learning\n",
    "\treframed = series_to_supervised(player_values, input_size, output_size, dropnan=True)\n",
    "\t# print(reframed.columns.tolist())\n",
    "\tmatchers = ['var10(t)', 'var10(t+']\n",
    "\tmatching = [s for s in reframed.columns.tolist() if any(xs in s for xs in matchers)]\n",
    "\t# print(matching)\n",
    "\tnew_cols = [col for col in reframed.columns if col not in matching] + matching\n",
    "\treframed = reframed[new_cols]\n",
    "\t# print(reframed.columns.tolist())\n",
    "\t# print(reframed.shape)\n",
    "\t# split into train and test sets\n",
    "\tvalues = reframed.values\n",
    "\ttrain = values[:train_size, :]\n",
    "\ttest = values[train_size:, :]\n",
    "\t# split into input and outputs\n",
    "\ttrain_X, train_y = train[:, :-output_size], train[:, -output_size:]\n",
    "\ttest_X, test_y = test[:, :-output_size], test[:, -output_size:]\n",
    "\t# print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "\tif model=='Naive':\n",
    "\t\t# print(train_y.mean())\n",
    "\t\tyhat_inversed = np.full(test_y.shape[0], train_y.mean())\n",
    "\t\t# print(yhat_inversed)\n",
    "\t\ttest_y = test_y.reshape((len(test_y), 1))\n",
    "\t\ttrain_y_inversed = train_y\n",
    "\t\ttest_y_inversed = test_y\n",
    "\t\ttrain_y_last = train_y_inversed[-1]\n",
    "\t\treturn test_y_inversed, yhat_inversed, values, train_y_last\n",
    "\n",
    "\t# scale X\n",
    "\tsc_x = StandardScaler()\n",
    "\ttrain_X = sc_x.fit_transform(train_X)\n",
    "\ttest_X = sc_x.transform(test_X)\n",
    "\t# scale y\n",
    "\tif output_size==1:\n",
    "\t\tsc_y = StandardScaler()\n",
    "\t\ttrain_y = sc_y.fit_transform(train_y.reshape(-1, 1))\n",
    "\t\ttest_y = sc_y.transform(test_y.reshape(-1, 1))\n",
    "\telse:\n",
    "\t\tsc_y = StandardScaler()\n",
    "\t\ttrain_y = sc_y.fit_transform(train_y)\n",
    "\t\ttest_y = sc_y.transform(test_y)\n",
    "\t# define model\n",
    "\tif model=='Linear Regression':\n",
    "\t\tif player_name=='Pedri': # avoid negative predictions\n",
    "\t\t\tmodel = LinearRegression(positive=True).fit(train_X, train_y)\n",
    "\t\telse:\n",
    "\t\t\tmodel = LinearRegression().fit(train_X, train_y)\n",
    "\t\tyhat = model.predict(test_X)\n",
    "\t\tyhat_inversed = sc_y.inverse_transform(yhat)\n",
    "\telif model=='Support Vector Machines':\n",
    "\t\tsvr_model = SVR()\n",
    "\t\tgrid = dict()\n",
    "\t\tgrid['C'] = [0.5, 0.7, 1]\n",
    "\t\tgrid['epsilon'] = [7e-2, 1e-1, 1.0]\n",
    "\t\tgrid['kernel'] = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\t\tsearch = GridSearchCV(svr_model, grid, cv=5, n_jobs=-1)\n",
    "\t\tstart = time.time()\n",
    "\t\tsearch.fit(train_X, train_y.ravel())\n",
    "\t\t# grid_svr_elapsedTime = time.time()-start\n",
    "\t\t# print(\"Tuning time: %.5f seconds\" % grid_svr_elapsedTime)\n",
    "\t\t# print(search.best_params_)\n",
    "\t\t\n",
    "\t\tmodel = SVR(kernel=search.best_params_['kernel'], C=search.best_params_['C'], \n",
    "\t\t\t\t\tepsilon=search.best_params_['epsilon']).fit(train_X, train_y.ravel())\n",
    "\t\tyhat = model.predict(test_X)\n",
    "\t\tyhat_inversed = sc_y.inverse_transform(yhat.reshape(-1, 1))\n",
    "\telif model=='Random Forest':\n",
    "\t\trf_model = RandomForestRegressor()\n",
    "\t\tgrid = dict()\n",
    "\t\tgrid['max_features'] = ['auto', 'sqrt', 'log2']\n",
    "\t\tgrid['min_samples_leaf'] = [1, 8, 15]\n",
    "\t\tgrid['min_samples_split'] = [2, 8, 14]\n",
    "\t\tgrid['n_estimators'] = [60, 80, 100, 120]\n",
    "\t\tsearch = GridSearchCV(rf_model, grid, cv=5, n_jobs=-1)\n",
    "\t\tstart = time.time()\n",
    "\t\tsearch.fit(train_X, train_y.ravel())\n",
    "\t\t# grid_rf_elapsedTime = time.time()-start\n",
    "\t\t# print(\"Tuning time: %.5f seconds\" % grid_rf_elapsedTime)\n",
    "\t\t# print(search.best_params_)\n",
    "\t\t\n",
    "\t\tmodel = RandomForestRegressor(max_features=search.best_params_['max_features'], min_samples_leaf=search.best_params_['min_samples_leaf'], \n",
    "\t\t\t\t\tmin_samples_split=search.best_params_['min_samples_split'],n_estimators=search.best_params_['n_estimators']).fit(train_X, train_y.ravel())\n",
    "\t\tyhat = model.predict(test_X)\n",
    "\t\tyhat_inversed = sc_y.inverse_transform(yhat.reshape(-1, 1))\n",
    "\telif model=='XGBoost':\n",
    "\t\txgb_model = xgboost.XGBRegressor()\n",
    "\t\tgrid = {\"subsample\":[0.5, 1],\n",
    "\t\t\t\t\"colsample_bytree\":[0.5, 1],\n",
    "\t\t\t\t\"max_depth\":[5, 6, 7, 8],\n",
    "\t\t\t\t\"min_child_weight\":[1,5],\n",
    "\t\t\t\t\"learning_rate\":[0.3, 0.09, 0.03]}\n",
    "\t\tsearch = GridSearchCV(xgb_model, grid, cv=5, n_jobs=-1)\n",
    "\t\tstart = time.time()\n",
    "\t\tsearch.fit(train_X, train_y.ravel())\n",
    "\t\t# grid_xgb_elapsedTime = time.time()-start\n",
    "\t\t# print(\"Tuning time: %.5f seconds\" % grid_xgb_elapsedTime)\n",
    "\t\t# print(search.best_params_)\n",
    "\n",
    "\t\tmodel = xgboost.XGBRegressor(subsample=search.best_params_['subsample'], colsample_bytree=search.best_params_['colsample_bytree'], \n",
    "\t\t\t\tmax_depth=search.best_params_['max_depth'], min_child_weight=search.best_params_['min_child_weight'],\n",
    "\t\t\t\tlearning_rate=search.best_params_['learning_rate']).fit(train_X, train_y.ravel())\n",
    "\t\tyhat = model.predict(test_X)\n",
    "\t\tyhat_inversed = sc_y.inverse_transform(yhat.reshape(-1, 1))\n",
    "\telif model=='MLP':\n",
    "\t\tmlp_model = MLPRegressor(early_stopping=True)\n",
    "\t\tgrid = dict()\n",
    "\t\tgrid = {\n",
    "\t\t\t'hidden_layer_sizes': [(50,50,50), (50,100,50), (50,100), (100,50), (100,)],\n",
    "\t\t\t'activation': ['tanh', 'relu'],\n",
    "\t\t\t'solver': ['sgd', 'adam'],\n",
    "\t\t\t'alpha': [0.0001, 0.05, 0.09],\n",
    "\t\t\t'learning_rate': ['constant','adaptive'],\n",
    "\t\t}\n",
    "\t\tsearch = GridSearchCV(mlp_model, grid, cv=5, n_jobs=-1)\n",
    "\t\tstart = time.time()\n",
    "\t\tsearch.fit(train_X, train_y.ravel())\n",
    "\t\t# grid_mlp_elapsedTime = time.time()-start\n",
    "\t\t# print(\"Tuning time: %.5f seconds\" % grid_mlp_elapsedTime)\n",
    "\t\t# print(search.best_params_)\n",
    "\n",
    "\t\tmodel = MLPRegressor(early_stopping=True, hidden_layer_sizes=search.best_params_['hidden_layer_sizes'], \n",
    "\t\t\t\tactivation=search.best_params_['activation'], solver=search.best_params_['solver'],\n",
    "\t\t\t\talpha=search.best_params_['alpha'],learning_rate=search.best_params_['learning_rate']).fit(train_X, train_y.ravel())\n",
    "\t\tyhat = model.predict(test_X)\n",
    "\t\tyhat_inversed = sc_y.inverse_transform(yhat.reshape(-1, 1))\n",
    "\n",
    "\n",
    "\ttest_y = test_y.reshape((len(test_y), 1))\n",
    "\ttrain_y_inversed = sc_y.inverse_transform(train_y)\n",
    "\ttest_y_inversed = sc_y.inverse_transform(test_y)\n",
    "\ttrain_y_last = train_y_inversed[-1]\n",
    "\treturn test_y_inversed, yhat_inversed, values, train_y_last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all models for each player and hold results/plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-18 14:10:52.757584: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-18 14:10:52.757708: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-18 14:10:52.757768: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (aspire-a315-56): /proc/driver/nvidia/version does not exist\n",
      "2022-07-18 14:10:52.760019: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 956ms/step\n",
      "Finished for:  Messi\n",
      "1/1 [==============================] - 1s 924ms/step\n",
      "Finished for:  Lewandowski\n",
      "1/1 [==============================] - 1s 513ms/step\n",
      "Finished for:  Jorginho\n",
      "1/1 [==============================] - 1s 722ms/step\n",
      "Finished for:  Benzema\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1d3f20a440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 731ms/step\n",
      "Finished for:  Kante\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1d2c188c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 980ms/step\n",
      "Finished for:  Cristiano\n",
      "1/1 [==============================] - 1s 568ms/step\n",
      "Finished for:  Salah\n",
      "1/1 [==============================] - 0s 404ms/step\n",
      "Finished for:  Debruyne\n",
      "1/1 [==============================] - 1s 589ms/step\n",
      "Finished for:  Mbappe\n",
      "1/1 [==============================] - 1s 599ms/step\n",
      "Finished for:  Donnarumma\n",
      "1/1 [==============================] - 1s 585ms/step\n",
      "Finished for:  Haaland\n",
      "1/1 [==============================] - 1s 598ms/step\n",
      "Finished for:  Lukaku\n",
      "1/1 [==============================] - 1s 616ms/step\n",
      "Finished for:  Chiellini\n",
      "1/1 [==============================] - 1s 563ms/step\n",
      "Finished for:  Bonucci\n",
      "1/1 [==============================] - 1s 752ms/step\n",
      "Finished for:  Sterling\n",
      "1/1 [==============================] - 1s 806ms/step\n",
      "Finished for:  Neymar\n",
      "1/1 [==============================] - 1s 670ms/step\n",
      "Finished for:  Suarez\n",
      "1/1 [==============================] - 1s 891ms/step\n",
      "Finished for:  Kjaer\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Finished for:  Mount\n",
      "1/1 [==============================] - 1s 802ms/step\n",
      "Finished for:  Mahrez\n",
      "1/1 [==============================] - 1s 826ms/step\n",
      "Finished for:  Bruno\n",
      "1/1 [==============================] - 1s 756ms/step\n",
      "Finished for:  Lautaro\n",
      "1/1 [==============================] - 1s 732ms/step\n",
      "Finished for:  Kane\n",
      "1/1 [==============================] - 1s 622ms/step\n",
      "Finished for:  Pedri\n",
      "1/1 [==============================] - 1s 515ms/step\n",
      "Finished for:  Foden\n",
      "1/1 [==============================] - 1s 906ms/step\n",
      "Finished for:  Moreno\n",
      "1/1 [==============================] - 1s 612ms/step\n",
      "Finished for:  Barella\n",
      "1/1 [==============================] - 1s 532ms/step\n",
      "Finished for:  Dias\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Finished for:  Modric\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "Finished for:  Azpilicueta\n",
      "CPU times: user 6h 23min 23s, sys: 6min 25s, total: 6h 29min 48s\n",
      "Wall time: 2h 54min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "model_evaluation = pd.DataFrame()\n",
    "\n",
    "LEAGUE_DATAPATH = '/.../data/all_players_league_match_info.csv'\n",
    "league_data = pd.read_csv(LEAGUE_DATAPATH, parse_dates=['startTimestamp', 'player_birth', 'previous_date'])\n",
    "league_data = league_data[['player_name','age',\\\n",
    "\t'fifa_rating','fifa_potential','after_injury','injury_days','rest_days',\\\n",
    "\t'current_team_category','opponent_category','home_fixture',\\\n",
    "\t'Performance']]\n",
    "# league_data\n",
    "names_list = league_data['player_name'].unique().tolist()\n",
    "# names_list=['Messi']\n",
    "\n",
    "for player_name in names_list:\n",
    "\tplayer_df = league_data[league_data['player_name']==player_name]\n",
    "\tplayer_df = player_df.drop(labels=['player_name'], axis=1, inplace=False)\n",
    "\t# player_df\n",
    "\tplayer_values = player_df.values\n",
    "\tinput_size = 1\n",
    "\toutput_size = 1\n",
    "\ttest_size = 10\n",
    "\ttrain_size = player_values.shape[0]-input_size-test_size\n",
    "\n",
    "\tplayer_evaluation = pd.DataFrame()\n",
    "\n",
    "\tfor i, model_name in enumerate(['Naive', 'Linear Regression', 'Support Vector Machines', 'Random Forest', 'XGBoost', 'MLP', 'LSTM']):\n",
    "\t\tif model_name=='LSTM':\n",
    "\t\t\ttest_y, pred_y, reframed_values, train_y_last = lstm_train_predict(player_values, input_size, output_size, train_size, player_name)\n",
    "\t\telse:\n",
    "\t\t\ttest_y, pred_y, reframed_values, train_y_last = train_predict(model_name, player_values, input_size, output_size, train_size, player_name)\n",
    "\t\tmae, mape, rmse, smaperror, r2 = get_metrics(test_y, pred_y)\n",
    "\t\t# print_metrics(mae, mape, rmse, smaperror, r2)\n",
    "\t\tif model_name != 'Naive':\n",
    "\t\t\tcorrect_pred_updowns = get_percentage(test_y, pred_y, train_y_last)\n",
    "\t\telse:\n",
    "\t\t\tcorrect_pred_updowns = 0\n",
    "\t\tresults = [{'Player': player_name, model_name+'_MAE': mae, model_name+'_RMSE': rmse, model_name+'_R-squared': r2, model_name+'_correct_pred_updowns': correct_pred_updowns}]\n",
    "\t\tplayer_evaluation = player_evaluation.append(results, ignore_index=True, sort=False)\n",
    "\t\tplayer_evaluation = player_evaluation.apply(lambda x: pd.Series(x.dropna().values))\n",
    "\t\tplayer_evaluation.dropna(inplace=True)\n",
    "\n",
    "\t\tvalues_y = reframed_values[:, -output_size:]\n",
    "\t\tdata = pd.Series(values_y.flatten())\n",
    "\t\tpredictions = pd.DataFrame(pred_y.flatten())\n",
    "\t\tpredictions.index = data[train_size:].index\n",
    "\t\tpredictions = predictions.rename(columns={0: \"Performance\"})\n",
    "\n",
    "\t\t#plot\n",
    "\t\tif i==0:\n",
    "\t\t\t# pass\n",
    "\t\t\tplot_train_test(data, train_size, player_name)\n",
    "\t\tplot_preds_real(data, predictions, train_size, player_name, model_name)\n",
    "\tprint('Finished for: ', player_name)\n",
    "\t\t\n",
    "\tplayer_evaluation.to_csv('results/'+player_name+'.csv')\n",
    "\tmodel_evaluation = pd.concat([model_evaluation, player_evaluation])\n",
    "\t\n",
    "model_evaluation.to_csv('results/'+'model_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.2] [7.119502]\n",
      "[6.5] [7.260408]\n",
      "[7.2] [7.2401104]\n",
      "[7.4] [7.1220856]\n",
      "[6.9] [7.2667465]\n",
      "[7.2] [7.269112]\n",
      "[7.2] [7.1855974]\n",
      "[7.4] [7.1487603]\n",
      "[6.5] [7.273168]\n",
      "[6.1] [7.137644]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_y)):\n",
    "    print(test_y[i],pred_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17a46f19d1db421aef12fa7769500ae9b5cbd26442453a35deeba8f32649aeb6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
